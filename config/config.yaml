
# Define the root directory for storing artifacts
artifacts_root: artifacts

# Configuration for data ingestion
data_ingestion:
  # Directory where data ingestion artifacts will be stored
  root_dir: artifacts/data_ingestion
  # URL to the source file containing the dataset (in this case, a Google Drive link)
  source_URL: https://drive.google.com/file/d/1vlhZ5c7abUKF8xXERIw6m9Te8fW7ohw3/view?usp=sharing # for binary classification
  # Path where the downloaded data file will be saved locally
  local_data_file: artifacts/data_ingestion/data.zip
  # Directory where the unzipped data will be stored
  unzip_dir: artifacts/data_ingestion

# Configuration for preparing the base model
prepare_base_model:
  # Directory for storing artifacts related to the base model preparation
  root_dir: artifacts/prepare_base_model
  # Path to the original base model file
  base_model_path: artifacts/prepare_base_model/base_model.h5
  # Path to the updated base model file after modifications
  updated_base_model_path: artifacts/prepare_base_model/base_model_updated.h5

# Configuration for training
training:
  # Directory for storing training artifacts
  root_dir: artifacts/training
  # Path where the trained model will be saved
  trained_model_path: artifacts/training/model.h5


